{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tools and Dependencies"
      ],
      "metadata": {
        "id": "WQZJsA6o7lTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3RstcW9q7P5H"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Rescaling, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os, zipfile\n",
        "import numpy as np\n",
        "from sklearn.metrics import (confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the Dataset"
      ],
      "metadata": {
        "id": "I0oCgXGgS4ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --no-checkout https://github.com/Agasthya-Samyak-Jnan/Diabetic-Neuropathy-Risk-ML.git\n",
        "%cd Diabetic-Neuropathy-Risk-ML\n",
        "!git sparse-checkout init --cone\n",
        "!git sparse-checkout set Datasets/Extended_Dataset\n",
        "!git checkout main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7631b807-8d46-426f-c5db-1d29e793186b",
        "id": "sPbSUQCRS4lo"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Diabetic-Neuropathy-Risk-ML'...\n",
            "remote: Enumerating objects: 27269, done.\u001b[K\n",
            "remote: Total 27269 (delta 0), reused 0 (delta 0), pack-reused 27269 (from 1)\u001b[K\n",
            "Receiving objects: 100% (27269/27269), 1.14 GiB | 16.28 MiB/s, done.\n",
            "Resolving deltas: 100% (1006/1006), done.\n",
            "/content/Diabetic-Neuropathy-Risk-ML\n",
            "Updating files: 100% (27990/27990), done.\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Parameters"
      ],
      "metadata": {
        "id": "8yyYCIk6S4lo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Config Parameters"
      ],
      "metadata": {
        "id": "TF8_7mJxY34H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "MODEL_NAME = \"MobileNetV2\"\n",
        "VERSION = \"Version-02\"\n",
        "train_dir = \"Datasets/Extended_Dataset/train\"\n",
        "val_dir   = \"Datasets/Extended_Dataset/val\""
      ],
      "metadata": {
        "id": "GsIuoFsJS4lo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "2y3umqOES4lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "LR = 1e-4\n",
        "FT_LR = 1e-5\n",
        "EPOCHS = 15\n",
        "FT_EPOCHS = 5\n",
        "tf.random.set_seed(42) # To reproduce same randomization\n",
        "np.random.seed(42)  # To reproduce same randomization"
      ],
      "metadata": {
        "id": "zAbCCfqfS4lq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset\n"
      ],
      "metadata": {
        "id": "-_5jGtcSS4lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data generator object to load dataset samples during training\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"binary\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"binary\"\n",
        ")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(AUTOTUNE)\n",
        "val_ds   = val_ds.prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9dad24-9262-4f8a-dc5d-a1fbc2b771a2",
        "id": "cGrPOjoRS4lo"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21660 files belonging to 2 classes.\n",
            "Found 6330 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "CLi4cSG1S4lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Normalize inside the model\n",
        "x = Rescaling(1./255)(inputs)\n",
        "\n",
        "# Pre-trained MobileNetV2 base\n",
        "base_model = MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_tensor=x  # pass normalized inputs here\n",
        ")\n",
        "\n",
        "base_model.trainable = False  # Phase 1: feature extraction\n",
        "\n",
        "# Add classification head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Define final model\n",
        "model = Model(inputs=inputs, outputs=output)"
      ],
      "metadata": {
        "id": "0gIneB2nS4lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6ae3f0-d6b4-4427-f432-3486b811b845"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3811952941.py:10: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "hjYW4xiLS4lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Initilaization or Pre-loading (if pre-trained)"
      ],
      "metadata": {
        "id": "F4vdE237S4lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")"
      ],
      "metadata": {
        "id": "2qZn9LynS4lr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training - Phase 1 (First Training)"
      ],
      "metadata": {
        "id": "uar79SK9S4lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daecd20b-efd8-4c3c-d717-6efd0072bf37",
        "id": "IjSpgWgeS4lr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 377ms/step - accuracy: 0.5621 - auc: 0.5913 - loss: 0.8247 - val_accuracy: 0.8556 - val_auc: 0.9351 - val_loss: 0.3625\n",
            "Epoch 2/15\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 201ms/step - accuracy: 0.7990 - auc: 0.8777 - loss: 0.4388 - val_accuracy: 0.8844 - val_auc: 0.9587 - val_loss: 0.2746\n",
            "Epoch 3/15\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 206ms/step - accuracy: 0.8546 - auc: 0.9288 - loss: 0.3385 - val_accuracy: 0.8946 - val_auc: 0.9645 - val_loss: 0.2459\n",
            "Epoch 4/15\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 200ms/step - accuracy: 0.8831 - auc: 0.9519 - loss: 0.2809 - val_accuracy: 0.8957 - val_auc: 0.9664 - val_loss: 0.2348\n",
            "Epoch 5/15\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 206ms/step - accuracy: 0.8986 - auc: 0.9644 - loss: 0.2452 - val_accuracy: 0.8984 - val_auc: 0.9677 - val_loss: 0.2274\n",
            "Epoch 6/15\n",
            "\u001b[1m 27/170\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 183ms/step - accuracy: 0.9086 - auc: 0.9682 - loss: 0.2318"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise training results\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(epochs, history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(epochs, history.history['val_accuracy'], label='Val Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Performance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(epochs, history.history['loss'], label='Train Loss')\n",
        "plt.plot(epochs, history.history['val_loss'], label='Val Loss')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Performance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# AUC\n",
        "plt.plot(epochs, history.history['auc'], label='Train AUC')\n",
        "plt.plot(epochs, history.history['val_auc'], label='Val AUC')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('AUC')\n",
        "plt.title('Training & Validation Performance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QECO05g4S4lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training - Phase 2 (Fine Tuning)"
      ],
      "metadata": {
        "id": "zpUmBhFAS4ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=FT_LR),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=FT_EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "8jAad73NS4ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Visualise training results\n",
        "epochs = range(1, len(history_finetune.history['loss']) + 1)\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(epochs, history_finetune.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(epochs, history_finetune.history['val_accuracy'], label='Val Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Performance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(epochs, history_finetune.history['loss'], label='Train Loss')\n",
        "plt.plot(epochs, history_finetune.history['val_loss'], label='Val Loss')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Performance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# AUC\n",
        "plt.plot(epochs, history_finetune.history['auc'], label='Train AUC')\n",
        "plt.plot(epochs, history_finetune.history['val_auc'], label='Val AUC')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('AUC')\n",
        "plt.title('Training & Validation Performance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pIbd1gOVS4ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Model"
      ],
      "metadata": {
        "id": "e3Yw4p5YRY4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute final evaluation metrics\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_prob = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    probs = model.predict(images, verbose=0)\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(preds)\n",
        "    y_prob.extend(probs)\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_prob = np.array(y_prob)\n",
        "\n",
        "# Confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "# Metrics\n",
        "accuracy  = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall    = recall_score(y_true, y_pred)\n",
        "f1        = f1_score(y_true, y_pred)\n",
        "auc       = roc_auc_score(y_true, y_prob)\n",
        "npv       = tn / (tn + fn)\n",
        "\n",
        "# Final validation loss (last epoch of fine-tuning)\n",
        "final_loss = history_finetune.history[\"val_loss\"][-1]\n",
        "\n",
        "print(f\"\"\"\n",
        "MODEL PERFORMANCE (Validation Set)\n",
        "\n",
        "Accuracy  : {accuracy:.5f}\n",
        "Precision : {precision:.5f}\n",
        "Recall    : {recall:.5f}\n",
        "F1-Score  : {f1:.5f}\n",
        "AUC       : {auc:.5f}\n",
        "NPV       : {npv:.5f}\n",
        "Loss      : {final_loss:.5f}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "YtxYIpQHRb9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation and Saving the Model"
      ],
      "metadata": {
        "id": "PA1fMiSfS4lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Version and base paths\n",
        "VERSION_NUMBER = VERSION[-2:]\n",
        "\n",
        "BASE_PATH = f\"{VERSION}\"\n",
        "STATS_DIR = os.path.join(BASE_PATH, \"Training Stats\")\n",
        "\n",
        "os.makedirs(STATS_DIR, exist_ok=True)\n",
        "\n",
        "# Save model (correct location + naming)\n",
        "model.save(f\"{MODEL_NAME}-base-model-v{VERSION_NUMBER}.keras\")\n",
        "MODEL_PATH = os.path.join(BASE_PATH,f\"{MODEL_NAME}-base-model-v{VERSION_NUMBER}.keras\")\n",
        "model.save(MODEL_PATH)\n",
        "\n",
        "# Save hyperparameters\n",
        "hyperparam_text = f\"\"\"\n",
        "Dataset Size = 27,990 Images\n",
        "Training Size = 21,660 Images (~77.4%)\n",
        "Validation Size = 6,330 Images (~22.6%)\n",
        "\n",
        "Input Image Size = {IMG_SIZE}x{IMG_SIZE}\n",
        "Batch Size = {BATCH_SIZE}\n",
        "\n",
        "Loss Function = Binary Crossentropy (BCE)\n",
        "Optimizer = Adam\n",
        "Learning Rate = {LR}\n",
        "Fine Tuning Learning Rate = {FT_LR}\n",
        "\n",
        "1st Training Epochs = {EPOCHS}\n",
        "Fine Tuning Epochs = {FT_EPOCHS}\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(BASE_PATH, f\"Hyperparameters-v{VERSION_NUMBER}.txt\"), \"w\") as f:\n",
        "    f.write(hyperparam_text.strip())\n",
        "\n",
        "# Save logs\n",
        "def save_log(history, filename):\n",
        "    with open(os.path.join(STATS_DIR, filename), \"w\") as f:\n",
        "        for k, v in history.history.items():\n",
        "            f.write(f\"{k}: {v}\\n\")\n",
        "\n",
        "save_log(history, \"first_training_log.txt\")\n",
        "save_log(history_finetune, \"fine_tuning_log.txt\")\n",
        "\n",
        "# Save plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_plot(history, metric, filename):\n",
        "    plt.figure()\n",
        "    plt.plot(history.history[metric], label=f\"Train {metric}\")\n",
        "    plt.plot(history.history[f\"val_{metric}\"], label=f\"Val {metric}\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric.upper())\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(STATS_DIR, filename))\n",
        "    plt.close()\n",
        "\n",
        "# Phase 1\n",
        "save_plot(history, \"accuracy\", \"1stTraining_Accuracy.png\")\n",
        "save_plot(history, \"loss\", \"1stTraining_Loss.png\")\n",
        "save_plot(history, \"auc\", \"1stTraining_AUC.png\")\n",
        "\n",
        "# Phase 2\n",
        "save_plot(history_finetune, \"accuracy\", \"FineTuning_Accuracy.png\")\n",
        "save_plot(history_finetune, \"loss\", \"FineTuning_Loss.png\")\n",
        "save_plot(history_finetune, \"auc\", \"FineTuning_AUC.png\")\n",
        "\n",
        "# Save final evaluation metrics\n",
        "performance_text = f\"\"\"\n",
        "MODEL PERFORMANCE (Validation Set)\n",
        "\n",
        "Accuracy  : {accuracy:.5f}\n",
        "Precision : {precision:.5f}\n",
        "Recall    : {recall:.5f}\n",
        "F1-Score  : {f1:.5f}\n",
        "AUC       : {auc:.5f}\n",
        "NPV       : {npv:.5f}\n",
        "Loss      : {final_loss:.5f}\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(BASE_PATH, \"model_performance.txt\"), \"w\") as f:\n",
        "    f.write(performance_text.strip())\n",
        "\n",
        "# Put everything into a Zip Folder\n",
        "ZIP_NAME = f\"{VERSION}.zip\"\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, _, file_list in os.walk(BASE_PATH):\n",
        "        for file in file_list:\n",
        "            full_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(full_path, BASE_PATH)\n",
        "            zipf.write(full_path, arcname)\n",
        "\n",
        "files.download(ZIP_NAME)"
      ],
      "metadata": {
        "id": "RNu9b-YiS4lt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}